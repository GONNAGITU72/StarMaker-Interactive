In this part, three models are generated to obtain word embedding matrix from a text corpus which is made up of the users' comments in the StarMaker app. First one is the skip-gram model with negative sampling, the second one is to train the embedding matrix in an LSTM model and the third one is the matrix factorization model. 
In order to test the model, we print out the top 8 most similar words for each test word. The similarity is computed by the coveriance of the trained word embedding matrixs. 
And the result shows that skip-gram model performs much better than the LSTM and matrix factorization methods.
