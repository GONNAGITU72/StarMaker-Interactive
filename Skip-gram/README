In this part, two models are tried to obtain word embedding matrix from a text corpus which comes from the comments in the StarMaker app. One is the skip-gram with negative sampling, and the other one is matrix factorization algorithm. In order to test the model, we print out the top 8 most similar words for each test word from the trained embedding matrixs. And the result shows that skip-gram model performs much better than the matrix factorization method.
